{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Pre-Processed Train / Test Data\n",
    "\n",
    "train_df = pd.read_csv('Train-Data.csv')\n",
    "test_df = pd.read_csv('Test-Data.csv')\n",
    "\n",
    "print(f'Train Length: {len(train_df)}, Test Length: {len(test_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Data For ML input\n",
    "trainx = np.array(train_df.iloc[:,:-1].values.tolist())\n",
    "trainy = np.array(train_df['label'].tolist())\n",
    "\n",
    "testx = np.array(test_df.iloc[:,:-1].values.tolist())\n",
    "testy = np.array(test_df['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validate Correct Input Shapes\n",
    "print(f'Trainx: {trainx.shape}, Trainy: {trainy.shape}')\n",
    "print(f'Testx: {testx.shape}, Testy: {testy.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode Classification Labels\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(trainy)\n",
    "\n",
    "trainy = le.transform(trainy)\n",
    "testy = le.transform(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Fully Connected Neural Network Model\n",
    "FCNN = Sequential()\n",
    "FCNN.add(Dense(32, input_dim=7, activation='relu'))\n",
    "FCNN.add(Dense(64, activation='relu'))\n",
    "FCNN.add(Dense(22, activation='softmax'))\n",
    "FCNN.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display Summary of Model Architecture\n",
    "FCNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the fully connected neural network\n",
    "FCNN.fit(trainx, trainy, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "FCNN_Preds = FCNN.predict(testx)\n",
    "FCNN_Preds = np.array([np.argmax(i) for i in FCNN_Preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance metrics functin\n",
    "def get_performance_metrics(preds):\n",
    "    metrics = {}\n",
    "    metrics['acc'] = accuracy_score(testy, preds)\n",
    "    metrics['prec'] = precision_score(testy, preds, average='macro')\n",
    "    metrics['rec'] = recall_score(testy, preds, average='macro')\n",
    "    metrics['f1'] = f1_score(testy, preds, average='macro')\n",
    "    metrics['cm'] = confusion_matrix(testy, preds)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate metrics\n",
    "FCNN_Metrics = get_performance_metrics(FCNN_Preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build CNN\n",
    "CNN = Sequential()\n",
    "CNN.add(Conv1D(filters=32, kernel_size=3, input_shape=(7, 1), activation='relu'))\n",
    "CNN.add(Flatten())\n",
    "CNN.add(Dense(128, activation='relu'))\n",
    "CNN.add(Dense(22, activation='softmax'))\n",
    "CNN.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape the x arrays to adapt to the input requirements of CNN. Train the CNN.\n",
    "trainx_reshaped = trainx.reshape(trainx.shape[0], 7, 1)\n",
    "testx_reshaped = testx.reshape(testx.shape[0], 7, 1)\n",
    "CNN.fit(trainx_reshaped, trainy, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make CNN Predictions\n",
    "CNN_Preds = CNN.predict(testx)\n",
    "CNN_Preds = np.array([np.argmax(i) for i in CNN_Preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate CNN Metrics\n",
    "CNN_Metrics = get_performance_metrics(CNN_Preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display both sets of metrics\n",
    "print(\"FCNN Metrics:\", {k:round(v, 3) for k,v in FCNN_Metrics.items() if k != 'cm'})\n",
    "print(\"CNN Metrics:\", {k:round(v, 3) for k,v in CNN_Metrics.items() if k != 'cm'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise Metrics\n",
    "FCNN_Dict = {k:round(v, 3) for k,v in FCNN_Metrics.items() if k != 'cm'}\n",
    "CNN_Dict = {k:round(v, 3) for k,v in CNN_Metrics.items() if k != 'cm'}\n",
    "\n",
    "labels = list(FCNN_Dict.keys())\n",
    "FCNN_vals = list(FCNN_Dict.values())\n",
    "CNN_vals = list(CNN_Dict.values())\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.3\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "rects1 = ax.bar(x - width, FCNN_vals, width, label='FCNN', alpha=0.7)\n",
    "rects2 = ax.bar(x, CNN_vals, width, label='CNN', alpha=0.7)\n",
    "\n",
    "ax.set_ylim(0.9, 1.0)\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_ylabel('Value')\n",
    "ax.set_title('Values by metric and model')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise Confuusion Matricess\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "cms = [FCNN_Metrics['cm'], CNN_Metrics['cm']]\n",
    "titles = ['FCNN', 'CNN']\n",
    "\n",
    "for ax, cm, title in zip(axes, cms, titles):\n",
    "\n",
    "    cax = ax.matshow(cm, cmap=plt.cm.Blues)\n",
    "    plt.colorbar(cax, ax=ax)\n",
    "    ax.set_title(title, pad=20)\n",
    "    ax.set_xticks(np.arange(len(le.classes_)))\n",
    "    ax.set_yticks(np.arange(len(le.classes_)))\n",
    "    ax.set_xticklabels(le.classes_, rotation=90)\n",
    "    ax.set_yticklabels(le.classes_)\n",
    "    \n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, str(cm[i, j]), ha='center', va='center', color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
